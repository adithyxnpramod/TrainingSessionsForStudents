{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithyxnpramod/TrainingSessionsForStudents/blob/main/DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "MP9RxQyBX_qA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the folder path in Google Drive\n",
        "drive_folder = \"/content/drive/MyDrive/mnist_data\"  # Folder to store MNIST dataset\n",
        "os.makedirs(drive_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
        "\n",
        "# Paths for saving CSV files\n",
        "train_csv_path = os.path.join(drive_folder, \"mnist_train.csv\")\n",
        "test_csv_path = os.path.join(drive_folder, \"mnist_test.csv\")\n",
        "\n",
        "# Check if the dataset already exists in Google Drive\n",
        "if os.path.exists(train_csv_path) and os.path.exists(test_csv_path):\n",
        "    print(\"Dataset already exists in Google Drive. Loading from CSV files...\")\n",
        "else:\n",
        "    # 3. Download the MNIST dataset\n",
        "    print(\"Downloading MNIST dataset...\")\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Normalize the pixel values to [0, 1]\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Flatten the images (28x28 -> 784)\n",
        "    x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "    x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    y_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "    y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "    # Combine features and labels into a single DataFrame\n",
        "    train_df = pd.DataFrame(np.hstack([x_train_flat, y_train_onehot]))\n",
        "    test_df = pd.DataFrame(np.hstack([x_test_flat, y_test_onehot]))\n",
        "\n",
        "    # Save to CSV in Google Drive\n",
        "    train_df.to_csv(train_csv_path, index=False, header=False)\n",
        "    test_df.to_csv(test_csv_path, index=False, header=False)\n",
        "\n",
        "    print(f\"Training data saved to {train_csv_path}\")\n",
        "    print(f\"Testing data saved to {test_csv_path}\")"
      ],
      "metadata": {
        "id": "miq1wibOZSw3",
        "outputId": "158fd65a-2507-448d-bf75-6afc60c67a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset already exists in Google Drive. Loading from CSV files...\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# 3. Read the CSV files back into memory\n",
        "import pandas as pd # Importing pandas here\n",
        "print(\"Loading dataset from Google Drive...\")\n",
        "train_data = pd.read_csv(train_csv_path, header=None)\n",
        "test_data = pd.read_csv(test_csv_path, header=None)\n",
        "\n",
        "# Separate features and labels\n",
        "x_train_csv = train_data.iloc[:, :-10].values  # First 784 columns are features\n",
        "y_train_csv = train_data.iloc[:, -10:].values  # Last 10 columns are one-hot labels\n",
        "\n",
        "x_test_csv = test_data.iloc[:, :-10].values\n",
        "y_test_csv = test_data.iloc[:, -10:].values"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "vdY_yaLnzRRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ec7b4e-ddb3-4796-9117-df6882c59a53"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset from Google Drive...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define the model\n",
        "model = keras.Sequential([\n",
        "    Flatten(input_shape=(28 * 28,)),  # Flatten input (784 features)\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 6. Train the model\n",
        "model.fit(x_train_csv, y_train_csv, epochs=5, batch_size=32)"
      ],
      "metadata": {
        "id": "KkiVpwGhYXBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06171447-f6c9-49fe-950c-36b020850dc6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8772 - loss: 0.4375\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1219\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0796\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.0574\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0437\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78b3e7a7d9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluate on test data\n",
        "loss, accuracy = model.evaluate(x_test_csv, y_test_csv, verbose=0)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n",
        "\n",
        "# 8. Make predictions (optional)\n",
        "predictions = model.predict(x_test_csv)\n",
        "predicted_labels = tf.argmax(predictions, axis=1)\n",
        "\n",
        "# Display first 10 predictions\n",
        "print(predicted_labels[:10])"
      ],
      "metadata": {
        "id": "W_FEHAxPYcjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915355ff-4361-49cc-fed8-ff934741238a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.08199544996023178\n",
            "Test accuracy: 0.9743000268936157\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "tf.Tensor([7 2 1 0 4 1 4 9 5 9], shape=(10,), dtype=int64)\n"
          ]
        }
      ]
    }
  ]
}